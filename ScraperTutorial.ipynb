{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of TikTok Scraper Code saved in ```TikTokScraper.py```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, I tried to use seleniumbase's api more. <br>\n",
    "Since we just want to scrape video info, we only have to manually log in once at the start of the code. I tried using guest mode to login, but it won't let me see the comment section so we'll have to log in ourselves. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```TikTokScraper.py``` info:\n",
    "- unlike proj1 where we had to interact with the For You page, this time we are just scraping video info. \n",
    "- Thus I used Seleniumbase's ```get_beautiful_soup()``` function to scrape the whole page and save it.\n",
    "- run the Testing file:\n",
    "```\n",
    "pytest TikTokScraper.py --html=\"report_test.html\"\n",
    "```\n",
    "-  when you run this code, a new folder is made with the current time as the name. \n",
    "- Each vido page is scraped and saved in this ```current_time``` folder as ```vid_index.html```, where the index is the index of the video in the ```video_list```. ex) vid_2.html is the 2nd video in the video list\n",
    "\n",
    "Great, now we have ```.html``` files with all the information, now we just have to extract the parts we want!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we scrape each video page and save it into each num.html file, we want to extract info out of the files now.  <br>\n",
    "We start with something simple: given one video html page, extract:\n",
    "1.  num of likes, shares, saves,comments, plays(new!) (in video box)\n",
    "2.  username, nickname, description, music  (below video box)\n",
    "3.  first batch of comments\n",
    "\n",
    "We will do this using ```BeautifulSoup```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./02-28-01-04-38/vid_0.html', 'r') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "    soup = BS(contents, \"html.parser\")\n",
    "    url = soup.find(\"meta\", property=\"og:url\")['content']\n",
    "    username = soup.find(\"span\", {\"class\": \"css-1c7urt-SpanUniqueId evv7pft1\"}).text\n",
    "    nickname = soup.find(\"span\", {\"class\": \"css-1xccqfx-SpanNickName e17fzhrb1\"}).text\n",
    "    description = soup.find(\"span\", {\"class\": \"css-j2a19r-SpanText efbd9f0\"}).text\n",
    "    music = soup.find(\"div\", {\"class\": \"css-pvx3oa-DivMusicText epjbyn3\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.tiktok.com/@pinkydollreal/video/7311845651862637829 \n",
      "username: pinkydollreal \n",
      "nickname: Pinkydoll \n",
      "description: NPC in the mall with  \n",
      "music: GTA San Andreas Theme - HYGH Lofi Music & Lobit & Cooky\n"
     ]
    }
   ],
   "source": [
    "print(\"url:\",url,\"\\nusername:\", username,\"\\nnickname:\", nickname, \"\\ndescription:\", description,\"\\nmusic:\",music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Imagine seeing pinky doll in the mall üò±', 'the fact this is laval', 'THEY NEED HER IN GTA 6-', 'I SAW THEMüò≠', 'Carrefour Laval spotted', 'iceeeee cream soooo goooddd', 'the random back flip üò≠üò≠', 'He did a whole back flip lol', 'oh noooo not in public right toooo', 'üò≠ she‚Äôs in laval?', 'This is a w collab', 'What is laval ü§î', 'Who came from Alibaba video', 'UMM CARREFOUR HOW DID I MISS THIS', 'I came here from the santa juju walk rizz vid', 'BYE NOT CARREFOUR', '@‚Çò·µ¢‚Çó‚Çë‚Çô‚Çê ü§ç not this too', '@kikiüîõüîù PINKY DOLL AT CF', '@breakinMcqueen95 @üíóÌòÑÏßÑ ÏïÑÎÇ¥üíó @Estriper literally at cf laval', 'Slay', '@Jaya‚∏Ü‚∏â it‚Äôs so preppy in here!', 'YES YES YES', '@Gabriella\\U0001fa77 at c4 agaibüòî', 'I swear I love me some pinkydoll ü´∂ü´∂', '@The best y/n BAHAHAHA', 'Is that car four Laval ?', 'like how Kris Kross did dat back flip', 'OMG YHU SAW ALIBABA I KNEW HE SAW YHU ON HIS VIDEO üò≠üò≠', \"üò≥ I'm a pray for you sis\", 'I was like yassss girl walk that walk', 'üò≠ this was more npc then an npc is', 'Roblox üôÇ', 'the flip was dope üòÖ', 'I sweater I have seen him on snapchat shorts', 'HES SO FRICKEN TINY', 'I love it!', '@ùìó‚Äô HEKP C CAREFOUR', 'Snapped', 'how are malls still in business?', 'You are so amazing']\n"
     ]
    }
   ],
   "source": [
    "comment_div = soup.find_all(\"p\", {\"class\": \"css-xm2h10-PCommentText e1g2efjf6\"})\n",
    "comments = []\n",
    "for comment in comment_div:\n",
    "    comments.append(comment.text)\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "like: 45500 \n",
      "share: 1205 \n",
      "comment: 744 \n",
      "play: 732700 \n",
      "collect: 2911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/w5dznchj3w9cyjt81v33hf1c0000gn/T/ipykernel_84872/2516979041.py:3: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  script_tag = soup.find('script', text=re.compile('stats'))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "script_tag = soup.find('script', text=re.compile('stats'))\n",
    "script_content = script_tag.string \n",
    "data = json.loads(script_content)[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct'][\"stats\"] #json to python dict, and keep looking\n",
    "like_count = data['diggCount']\n",
    "share_count = data['shareCount']\n",
    "comment_count = data['commentCount']\n",
    "playCount = data['playCount']\n",
    "collectCount = data['collectCount']\n",
    "print(\"\\nlike:\",like_count, \"\\nshare:\",share_count, \"\\ncomment:\", comment_count, \"\\nplay:\", playCount, \"\\ncollect:\", collectCount)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we **generalize** this code to loop through all the ```.html``` files. We do this in  ```parse_html.py```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Troubleshooting <br> </h3>\n",
    "known issues: <br>\n",
    "1. close popup on bottom right\n",
    "3. Even though we are logged in, TikTok **asks you to solve Captcha to proceed randomly**, so pay attention to the console message!\n",
    "![captcha](./assets/captcha.png)\n",
    "![console message](./assets/console_m_captcha.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "998e054e2a336645a1c034d50f95524bbbabc00cc66740a3f3687176c9a2862f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
