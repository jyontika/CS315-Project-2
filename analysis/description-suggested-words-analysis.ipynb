{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Description and Suggest Words\n",
    "\n",
    "Notebook to analyze text description + suggested words come the closest to NYT headlines for that day (as calculated by running cosine similarity on the text embeddings of both groups). [You‚Äôll manually inspect some posts to define the range of cosine similarity that makes sense the most.]\n",
    "\n",
    "**Author: Audrey Yip**\n",
    "\n",
    "**Table of Contents**\n",
    "1. [Read in data](#1)\n",
    "2. [Process description and suggested words](#2)\n",
    "3. [Create .csvs and get headline and keyword data](#3)     \n",
    "4. [Cosine similarity with Semantic Analysis](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in user data <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "This section will be fixed once we have all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_locationcreated</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_diggcount</th>\n",
       "      <th>video_sharecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>video_playcount</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_is_ad</th>\n",
       "      <th>video_stickers</th>\n",
       "      <th>author_username</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_followercount</th>\n",
       "      <th>author_followingcount</th>\n",
       "      <th>author_heartcount</th>\n",
       "      <th>author_videocount</th>\n",
       "      <th>author_diggcount</th>\n",
       "      <th>author_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jadeüêânot perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jadeüêânot perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26T06:32:40</td>\n",
       "      <td>15.0</td>\n",
       "      <td>PH</td>\n",
       "      <td>angels in tibet, Jam Republic, angels in tibet...</td>\n",
       "      <td>419100.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>üß†üß†üß†</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clarkie_cpm</td>\n",
       "      <td>Clarkie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jadeüêânot perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02T12:23:48</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Dream Academy, angels in tibet, Adela Dream Ac...</td>\n",
       "      <td>142700.0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>s/o to dream academy for teaching me how to da...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adelajergova</td>\n",
       "      <td>AD√âLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id      video_timestamp  video_duration  \\\n",
       "0  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "1  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "2  7283080657893379334  2023-09-26T06:32:40            15.0   \n",
       "3  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "4  7285397643725983008  2023-10-02T12:23:48            37.0   \n",
       "\n",
       "  video_locationcreated                                    suggested_words  \\\n",
       "0                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "1                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "2                    PH  angels in tibet, Jam Republic, angels in tibet...   \n",
       "3                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "4                    US  Dream Academy, angels in tibet, Adela Dream Ac...   \n",
       "\n",
       "   video_diggcount  video_sharecount  video_commentcount  video_playcount  \\\n",
       "0         356300.0            5606.0               986.0        2000000.0   \n",
       "1         356300.0            5606.0               986.0        2000000.0   \n",
       "2         419100.0            3518.0               708.0        2600000.0   \n",
       "3         356300.0            5606.0               986.0        2000000.0   \n",
       "4         142700.0            1373.0               551.0        1000000.0   \n",
       "\n",
       "                                   video_description  video_is_ad  \\\n",
       "0  Replying to @jadeüêânot perfect yet &  i made a ...        False   \n",
       "1  Replying to @jadeüêânot perfect yet &  i made a ...        False   \n",
       "2                                                üß†üß†üß†        False   \n",
       "3  Replying to @jadeüêânot perfect yet &  i made a ...        False   \n",
       "4  s/o to dream academy for teaching me how to da...        False   \n",
       "\n",
       "   video_stickers author_username author_name  author_followercount  \\\n",
       "0             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "1             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "2             NaN     clarkie_cpm     Clarkie                   NaN   \n",
       "3             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "4             NaN    adelajergova       AD√âLA                   NaN   \n",
       "\n",
       "   author_followingcount  author_heartcount  author_videocount  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4                    NaN                NaN                NaN   \n",
       "\n",
       "   author_diggcount  author_verified  \n",
       "0               NaN            False  \n",
       "1               NaN            False  \n",
       "2               NaN            False  \n",
       "3               NaN            False  \n",
       "4               NaN            False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix when we have metadata for all videos!\n",
    "cwd = os.getcwd()\n",
    "metadata_dir = f'{cwd}/../pre-processing/metadata-csv'\n",
    "metadata_files = [file for file in os.listdir(metadata_dir) if file.endswith(\".csv\")]\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in metadata_files:\n",
    "    file_path = os.path.join(metadata_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process video_description and suggested_words <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_description</th>\n",
       "      <th>suggested_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>Replying to @jadeüêânot perfect yet &amp;  i made a ...</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26T06:32:40</td>\n",
       "      <td>üß†üß†üß†</td>\n",
       "      <td>angels in tibet, Jam Republic, angels in tibet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02T12:23:48</td>\n",
       "      <td>s/o to dream academy for teaching me how to da...</td>\n",
       "      <td>Dream Academy, angels in tibet, Adela Dream Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7231292396573641991</td>\n",
       "      <td>2023-05-09T17:07:50</td>\n",
       "      <td>i hate my job pt 8 i think bro its 5 am goofy ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7235928808166100242</td>\n",
       "      <td>2023-05-22T04:59:26</td>\n",
       "      <td>i got my eyes on food</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id      video_timestamp  \\\n",
       "0  7273221955937914155  2023-08-30T16:56:01   \n",
       "2  7283080657893379334  2023-09-26T06:32:40   \n",
       "4  7285397643725983008  2023-10-02T12:23:48   \n",
       "5  7231292396573641991  2023-05-09T17:07:50   \n",
       "6  7235928808166100242  2023-05-22T04:59:26   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  Replying to @jadeüêânot perfect yet &  i made a ...   \n",
       "2                                                üß†üß†üß†   \n",
       "4  s/o to dream academy for teaching me how to da...   \n",
       "5  i hate my job pt 8 i think bro its 5 am goofy ...   \n",
       "6                              i got my eyes on food   \n",
       "\n",
       "                                     suggested_words  \n",
       "0  angels in tibet, angels in tibet dance, angels...  \n",
       "2  angels in tibet, Jam Republic, angels in tibet...  \n",
       "4  Dream Academy, angels in tibet, Adela Dream Ac...  \n",
       "5                                                NaN  \n",
       "6                                                NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Eni's csv for now to practice analysis\n",
    "\n",
    "## filter out videos that are not created in us\n",
    "\n",
    "# access relevant columns\n",
    "df_filtered = combined_df[['video_id', 'video_timestamp', 'video_description', 'suggested_words']]\n",
    "\n",
    "# only take unique videos\n",
    "df_filtered_no_dup = df_filtered.drop_duplicates(subset=['video_id'])\n",
    "df_filtered_no_dup.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/5mz_1h8j5c31x__pd0t4xhxw0000gn/T/ipykernel_66468/2413966399.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered_no_dup['video_date'] = df_filtered_no_dup['video_timestamp'].str[:10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_description</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>Replying to @jadeüêânot perfect yet &amp;  i made a ...</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>2023-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26T06:32:40</td>\n",
       "      <td>üß†üß†üß†</td>\n",
       "      <td>angels in tibet, Jam Republic, angels in tibet...</td>\n",
       "      <td>2023-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02T12:23:48</td>\n",
       "      <td>s/o to dream academy for teaching me how to da...</td>\n",
       "      <td>Dream Academy, angels in tibet, Adela Dream Ac...</td>\n",
       "      <td>2023-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7231292396573641991</td>\n",
       "      <td>2023-05-09T17:07:50</td>\n",
       "      <td>i hate my job pt 8 i think bro its 5 am goofy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7235928808166100242</td>\n",
       "      <td>2023-05-22T04:59:26</td>\n",
       "      <td>i got my eyes on food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id      video_timestamp  \\\n",
       "0  7273221955937914155  2023-08-30T16:56:01   \n",
       "2  7283080657893379334  2023-09-26T06:32:40   \n",
       "4  7285397643725983008  2023-10-02T12:23:48   \n",
       "5  7231292396573641991  2023-05-09T17:07:50   \n",
       "6  7235928808166100242  2023-05-22T04:59:26   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  Replying to @jadeüêânot perfect yet &  i made a ...   \n",
       "2                                                üß†üß†üß†   \n",
       "4  s/o to dream academy for teaching me how to da...   \n",
       "5  i hate my job pt 8 i think bro its 5 am goofy ...   \n",
       "6                              i got my eyes on food   \n",
       "\n",
       "                                     suggested_words  video_date  \n",
       "0  angels in tibet, angels in tibet dance, angels...  2023-08-30  \n",
       "2  angels in tibet, Jam Republic, angels in tibet...  2023-09-26  \n",
       "4  Dream Academy, angels in tibet, Adela Dream Ac...  2023-10-02  \n",
       "5                                                NaN  2023-05-09  \n",
       "6                                                NaN  2023-05-22  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column with just the dates\n",
    "df_filtered_no_dup['video_date'] = df_filtered_no_dup['video_timestamp'].str[:10]\n",
    "df_filtered_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load stop_words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# create list of hashtags to omit, we will not expect to find these in headlines\n",
    "stop_hashtags = ['fyp', 'foryou']\n",
    "\n",
    "def clean_description(description):\n",
    "    \"\"\"\n",
    "    Helper function, takes video description and splits into words, removes punctuation, emojis and stop words.\n",
    "    \"\"\"\n",
    "    if pd.isna(description):  \n",
    "        return [] \n",
    "    \n",
    "    # remove numbers from the text\n",
    "    description = re.sub(r'\\d+', '', description)\n",
    "\n",
    "    # split the description into words\n",
    "    words = description.split()\n",
    "    \n",
    "    # remove punctuation and emojis, make everything lowercase\n",
    "    cleaned_words = [re.sub(r'[^\\w\\s]', '', word).lower() for word in words]\n",
    "    \n",
    "    # remove stop words and words containing stop hashtags\n",
    "    cleaned_words = [word for word in cleaned_words if word not in stop_words and not any(stop_tag in word for stop_tag in stop_hashtags)]\n",
    "\n",
    "    # remove empty strings\n",
    "    cleaned_words = [word for word in cleaned_words if word]\n",
    "    \n",
    "    return cleaned_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'love',\n",
       " 'love',\n",
       " 'little',\n",
       " 'life',\n",
       " 'gotta',\n",
       " 'jump',\n",
       " 'hoops',\n",
       " 'sh',\n",
       " 'already',\n",
       " 'greenscreen',\n",
       " 'americacore',\n",
       " 'americacore',\n",
       " 'robbed',\n",
       " 'stolenwallet']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test clean description\n",
    "clean_description('love Love LOVE this little life üòç now i gotta jump through hoops for sh i already had ‚ò∫Ô∏èü§çüòçü´∂üòö #greenscreen #americacoreüöòüèàüçîüá∫üá∏ #americacoreü•∫üíó #foryou #robbed #stolenwallet #fyp„Ç∑ #fypp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sugg_words(sugg_words):\n",
    "    \"\"\"\n",
    "    Helper function, takes suggested words and splits into words, converts to lowercase and removes stop words.\n",
    "    \"\"\"\n",
    "    if pd.isna(sugg_words):  \n",
    "        return [] \n",
    "    \n",
    "    # remove numbers from the text\n",
    "    sugg_words = re.sub(r'\\d+', '', sugg_words)\n",
    "    \n",
    "    # split the suggested words into individual words\n",
    "    words = sugg_words.split(',')\n",
    "    \n",
    "    # split each word by white space\n",
    "    words = [sub_word.strip().lower() for word in words for sub_word in word.split()]\n",
    "\n",
    "    # convert each word to lowercase and remove  whitespace\n",
    "    words = [word.strip().lower() for word in words]\n",
    "    \n",
    "    # remove stop words\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['things',\n",
       " 'dont',\n",
       " 'prepare',\n",
       " 'big',\n",
       " 'sister',\n",
       " 'things',\n",
       " 'prepare',\n",
       " 'big',\n",
       " 'brother',\n",
       " 'things',\n",
       " 'dont',\n",
       " 'prepare',\n",
       " 'little',\n",
       " 'sister',\n",
       " 'prepare',\n",
       " 'older',\n",
       " 'sister',\n",
       " 'older',\n",
       " 'sister',\n",
       " 'little',\n",
       " 'brother',\n",
       " 'things',\n",
       " 'prepare',\n",
       " 'little',\n",
       " 'brother',\n",
       " 'things',\n",
       " 'dont',\n",
       " 'prepare',\n",
       " 'older',\n",
       " 'sister',\n",
       " 'things',\n",
       " 'prepare',\n",
       " 'big',\n",
       " 'sister',\n",
       " 'big',\n",
       " 'sister',\n",
       " 'little',\n",
       " 'brother',\n",
       " 'brother']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test suggested words function\n",
    "sugg_words = \"things they dont prepare you for as a big sister, things they don't prepare you for as a big brother, things they dont prepare you for as a little sister, what they don't prepare you for as an older sister, older sister and little brother, things they don't prepare you for as a little brother, things they dont prepare you for as an older sister, things they don't prepare you as a big sister, Big Sister And Little Brother, me and my brother\"\n",
    "clean_sugg_words(sugg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/5mz_1h8j5c31x__pd0t4xhxw0000gn/T/ipykernel_66468/411232085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered_no_dup['keywords'] = df_filtered_no_dup['suggested_words'].apply(clean_sugg_words) + df_filtered_no_dup['video_description'].apply(clean_description)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_description</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_date</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>Replying to @jadeüêânot perfect yet &amp;  i made a ...</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>[angels, tibet, angels, tibet, dance, angels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26T06:32:40</td>\n",
       "      <td>üß†üß†üß†</td>\n",
       "      <td>angels in tibet, Jam Republic, angels in tibet...</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>[angels, tibet, jam, republic, angels, tibet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02T12:23:48</td>\n",
       "      <td>s/o to dream academy for teaching me how to da...</td>\n",
       "      <td>Dream Academy, angels in tibet, Adela Dream Ac...</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>[dream, academy, angels, tibet, adela, dream, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7231292396573641991</td>\n",
       "      <td>2023-05-09T17:07:50</td>\n",
       "      <td>i hate my job pt 8 i think bro its 5 am goofy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>[hate, job, pt, think, bro, goofy, ass, audio]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7235928808166100242</td>\n",
       "      <td>2023-05-22T04:59:26</td>\n",
       "      <td>i got my eyes on food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>[got, eyes, food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id      video_timestamp  \\\n",
       "0  7273221955937914155  2023-08-30T16:56:01   \n",
       "2  7283080657893379334  2023-09-26T06:32:40   \n",
       "4  7285397643725983008  2023-10-02T12:23:48   \n",
       "5  7231292396573641991  2023-05-09T17:07:50   \n",
       "6  7235928808166100242  2023-05-22T04:59:26   \n",
       "\n",
       "                                   video_description  \\\n",
       "0  Replying to @jadeüêânot perfect yet &  i made a ...   \n",
       "2                                                üß†üß†üß†   \n",
       "4  s/o to dream academy for teaching me how to da...   \n",
       "5  i hate my job pt 8 i think bro its 5 am goofy ...   \n",
       "6                              i got my eyes on food   \n",
       "\n",
       "                                     suggested_words  video_date  \\\n",
       "0  angels in tibet, angels in tibet dance, angels...  2023-08-30   \n",
       "2  angels in tibet, Jam Republic, angels in tibet...  2023-09-26   \n",
       "4  Dream Academy, angels in tibet, Adela Dream Ac...  2023-10-02   \n",
       "5                                                NaN  2023-05-09   \n",
       "6                                                NaN  2023-05-22   \n",
       "\n",
       "                                            keywords  \n",
       "0  [angels, tibet, angels, tibet, dance, angels, ...  \n",
       "2  [angels, tibet, jam, republic, angels, tibet, ...  \n",
       "4  [dream, academy, angels, tibet, adela, dream, ...  \n",
       "5     [hate, job, pt, think, bro, goofy, ass, audio]  \n",
       "6                                  [got, eyes, food]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply helper functions to create new column in dataframe\n",
    "df_filtered_no_dup['keywords'] = df_filtered_no_dup['suggested_words'].apply(clean_sugg_words) + df_filtered_no_dup['video_description'].apply(clean_description)\n",
    "df_filtered_no_dup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create .csvs and get headline and keyword data <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_nyt_articles import filter_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis\n",
      "NYT directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis/../pre-processing/nyt-articles\n",
      "NYT data for 2023-12-22 already in folder\n"
     ]
    }
   ],
   "source": [
    "df = filter_by_date('2023-12-22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>headline</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>section_name</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bond prices are up. Nobody knows why, but it‚Äôs...</td>\n",
       "      <td>It‚Äôs been a strange few days on the Donald Tru...</td>\n",
       "      <td>A Christmas Gift From the Bond Market</td>\n",
       "      <td>2023-12-22T00:00:08+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>Op-Ed</td>\n",
       "      <td>United States Economy;Stocks and Bonds;Inflati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Some lawmakers are likely to oppose the move, ...</td>\n",
       "      <td>The Biden administration is preparing to relax...</td>\n",
       "      <td>U.S. Prepares to Lift Ban on Sales of Offensiv...</td>\n",
       "      <td>2023-12-22T00:24:41+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>News</td>\n",
       "      <td>United States Politics and Government;United S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The successful petition is one of the few rece...</td>\n",
       "      <td>The widow of Jamal Khashoggi, the Washington P...</td>\n",
       "      <td>Widow of Jamal Khashoggi Is Granted Political ...</td>\n",
       "      <td>2023-12-22T00:29:29+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>News</td>\n",
       "      <td>Khashoggi, Jamal;Khashoggi, Hanan Elatr;Asylum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The officers were charged over the 2020 death ...</td>\n",
       "      <td>A jury found three Tacoma police officers not ...</td>\n",
       "      <td>3 Tacoma Police Officers Cleared in Death of a...</td>\n",
       "      <td>2023-12-22T01:04:18+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>News</td>\n",
       "      <td>Police Brutality, Misconduct and Shootings;Ell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The company that operates Pornhub and other ad...</td>\n",
       "      <td>The company that operates Pornhub and other ad...</td>\n",
       "      <td>Pornhub‚Äôs Parent Company Admits to Profiting F...</td>\n",
       "      <td>2023-12-22T01:35:18+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>New York</td>\n",
       "      <td>News</td>\n",
       "      <td>Compensation for Damages (Law);Pornhub;Pornogr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           abstract  \\\n",
       "0           0  Bond prices are up. Nobody knows why, but it‚Äôs...   \n",
       "1           1  Some lawmakers are likely to oppose the move, ...   \n",
       "2           2  The successful petition is one of the few rece...   \n",
       "3           3  The officers were charged over the 2020 death ...   \n",
       "4           4  The company that operates Pornhub and other ad...   \n",
       "\n",
       "                                      lead_paragraph  \\\n",
       "0  It‚Äôs been a strange few days on the Donald Tru...   \n",
       "1  The Biden administration is preparing to relax...   \n",
       "2  The widow of Jamal Khashoggi, the Washington P...   \n",
       "3  A jury found three Tacoma police officers not ...   \n",
       "4  The company that operates Pornhub and other ad...   \n",
       "\n",
       "                                            headline  \\\n",
       "0              A Christmas Gift From the Bond Market   \n",
       "1  U.S. Prepares to Lift Ban on Sales of Offensiv...   \n",
       "2  Widow of Jamal Khashoggi Is Granted Political ...   \n",
       "3  3 Tacoma Police Officers Cleared in Death of a...   \n",
       "4  Pornhub‚Äôs Parent Company Admits to Profiting F...   \n",
       "\n",
       "                   pub_date document_type section_name type_of_material  \\\n",
       "0  2023-12-22T00:00:08+0000       article      Opinion            Op-Ed   \n",
       "1  2023-12-22T00:24:41+0000       article         U.S.             News   \n",
       "2  2023-12-22T00:29:29+0000       article         U.S.             News   \n",
       "3  2023-12-22T01:04:18+0000       article         U.S.             News   \n",
       "4  2023-12-22T01:35:18+0000       article     New York             News   \n",
       "\n",
       "                                            keywords  \n",
       "0  United States Economy;Stocks and Bonds;Inflati...  \n",
       "1  United States Politics and Government;United S...  \n",
       "2  Khashoggi, Jamal;Khashoggi, Hanan Elatr;Asylum...  \n",
       "3  Police Brutality, Misconduct and Shootings;Ell...  \n",
       "4  Compensation for Damages (Law);Pornhub;Pornogr...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test analysis with this df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_keywords(text):\n",
    "    \"\"\"Split text into individual keywords based on whitespace and punctuation, remove stop words\"\"\"\n",
    "    if pd.isna(text):  # check if text is NaN\n",
    "        return []  \n",
    "    \n",
    "    # split text into individual keywords based on whitespace and punctuation\n",
    "    keywords = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    # remove stop words\n",
    "    cleaned_words = [word.lower() for word in keywords if word not in stop_words]\n",
    "    \n",
    "    return cleaned_words\n",
    "\n",
    "def clean_headline(text):\n",
    "    \"\"\"Split headline into individual words based on whitespace and punctuation, remove stop words\"\"\"\n",
    "    if pd.isna(text):  # check if text is NaN\n",
    "        return []  \n",
    "    \n",
    "    # remove numbers from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # split text into individual keywords based on whitespace and punctuation\n",
    "    keywords = text.split()\n",
    "\n",
    "    # remove stop words\n",
    "    cleaned_words = [word.lower() for word in keywords if word not in stop_words]\n",
    "    \n",
    "    return cleaned_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compensation', 'damages', 'law', 'pornhub']\n",
      "['tacoma', 'police', 'officers', 'cleared', 'death']\n"
     ]
    }
   ],
   "source": [
    "# test functions\n",
    "print(split_keywords('Compensation for Damages (Law);Pornhub;'))\n",
    "\n",
    "print(clean_headline('3 Tacoma Police Officers Cleared in Death of a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_date</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>[angels, tibet, angels, tibet, dance, angels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>[angels, tibet, jam, republic, angels, tibet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>[dream, academy, angels, tibet, adela, dream, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7231292396573641991</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>[hate, job, pt, think, bro, goofy, ass, audio]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7235928808166100242</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>[got, eyes, food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id  video_date  \\\n",
       "0  7273221955937914155  2023-08-30   \n",
       "2  7283080657893379334  2023-09-26   \n",
       "4  7285397643725983008  2023-10-02   \n",
       "5  7231292396573641991  2023-05-09   \n",
       "6  7235928808166100242  2023-05-22   \n",
       "\n",
       "                                            keywords  \n",
       "0  [angels, tibet, angels, tibet, dance, angels, ...  \n",
       "2  [angels, tibet, jam, republic, angels, tibet, ...  \n",
       "4  [dream, academy, angels, tibet, adela, dream, ...  \n",
       "5     [hate, job, pt, think, bro, goofy, ass, audio]  \n",
       "6                                  [got, eyes, food]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df_filtered_no_dup.head()\n",
    "test_df = test_df[['video_id', 'video_date', 'keywords']]\n",
    "test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis\n",
      "NYT directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis/../pre-processing/nyt-articles\n",
      "NYT data for 2023-08-30 already in folder\n",
      "Current working directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis\n",
      "NYT directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis/../pre-processing/nyt-articles\n",
      "NYT data for 2023-09-26 already in folder\n",
      "Current working directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis\n",
      "NYT directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis/../pre-processing/nyt-articles\n",
      "NYT data for 2023-10-02 already in folder\n",
      "Current working directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis\n",
      "NYT directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis/../pre-processing/nyt-articles\n",
      "NYT data for 2023-05-09 already in folder\n",
      "Current working directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis\n",
      "NYT directory: /Users/audreyyip/Desktop/CS 315/Project 2/Project 2 Repo/analysis/../pre-processing/nyt-articles\n",
      "NYT data for 2023-05-22 already in folder\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_date</th>\n",
       "      <th>video_keywords</th>\n",
       "      <th>nyt_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>[angels, tibet, angels, tibet, dance, angels, ...</td>\n",
       "      <td>[floyd, willie, lewis, iii, trump, donald, j, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>[angels, tibet, jam, republic, angels, tibet, ...</td>\n",
       "      <td>[presidential, election, 2024, debates, politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>[dream, academy, angels, tibet, adela, dream, ...</td>\n",
       "      <td>[national, parks, monuments, seashores, bears,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7231292396573641991</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>[hate, job, pt, think, bro, goofy, ass, audio]</td>\n",
       "      <td>[canada, china, politics, government, diplomat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7235928808166100242</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>[got, eyes, food]</td>\n",
       "      <td>[hiring, promotion, writing, writers, names, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id  video_date  \\\n",
       "0  7273221955937914155  2023-08-30   \n",
       "1  7283080657893379334  2023-09-26   \n",
       "2  7285397643725983008  2023-10-02   \n",
       "3  7231292396573641991  2023-05-09   \n",
       "4  7235928808166100242  2023-05-22   \n",
       "\n",
       "                                      video_keywords  \\\n",
       "0  [angels, tibet, angels, tibet, dance, angels, ...   \n",
       "1  [angels, tibet, jam, republic, angels, tibet, ...   \n",
       "2  [dream, academy, angels, tibet, adela, dream, ...   \n",
       "3     [hate, job, pt, think, bro, goofy, ass, audio]   \n",
       "4                                  [got, eyes, food]   \n",
       "\n",
       "                                        nyt_keywords  \n",
       "0  [floyd, willie, lewis, iii, trump, donald, j, ...  \n",
       "1  [presidential, election, 2024, debates, politi...  \n",
       "2  [national, parks, monuments, seashores, bears,...  \n",
       "3  [canada, china, politics, government, diplomat...  \n",
       "4  [hiring, promotion, writing, writers, names, p...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store rows\n",
    "rows = []\n",
    "\n",
    "# Iterate over each row in the video DataFrame\n",
    "for index, row in test_df.iterrows():\n",
    "    # Get relevant NYT articles using the video date\n",
    "    nyt_df = filter_by_date(row['video_date'])\n",
    "\n",
    "    # get relevant keywords and combine lists\n",
    "    keywords_list = nyt_df['keywords'].apply(split_keywords)\n",
    "    headline_list = nyt_df['headline'].apply(clean_headline)\n",
    "\n",
    "    combined_list = [keyword + headline for keyword, headline in zip(keywords_list, headline_list)]\n",
    "    flat_list = []\n",
    "    [flat_list.extend(item) for item in combined_list]\n",
    "    \n",
    "    # Process the data and create a new row\n",
    "    new_row = {\n",
    "        'video_id': row['video_id'],\n",
    "        'video_date': row['video_date'],\n",
    "        'video_keywords': row['keywords'],\n",
    "        'nyt_keywords': flat_list\n",
    "    }\n",
    "    \n",
    "    # Append the new row to the list of rows\n",
    "    rows.append(new_row)\n",
    "\n",
    "# Create DataFrame from the list of rows\n",
    "comparison_df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_date</th>\n",
       "      <th>video_keywords</th>\n",
       "      <th>nyt_keywords</th>\n",
       "      <th>video_sentences</th>\n",
       "      <th>nyt_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>[angels, tibet, angels, tibet, dance, angels, ...</td>\n",
       "      <td>[floyd, willie, lewis, iii, trump, donald, j, ...</td>\n",
       "      <td>angels tibet angels tibet dance angels tibet s...</td>\n",
       "      <td>floyd willie lewis iii trump donald j willis f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>[angels, tibet, jam, republic, angels, tibet, ...</td>\n",
       "      <td>[presidential, election, 2024, debates, politi...</td>\n",
       "      <td>angels tibet jam republic angels tibet tutoria...</td>\n",
       "      <td>presidential election 2024 debates political r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>[dream, academy, angels, tibet, adela, dream, ...</td>\n",
       "      <td>[national, parks, monuments, seashores, bears,...</td>\n",
       "      <td>dream academy angels tibet adela dream academy...</td>\n",
       "      <td>national parks monuments seashores bears death...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7231292396573641991</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>[hate, job, pt, think, bro, goofy, ass, audio]</td>\n",
       "      <td>[canada, china, politics, government, diplomat...</td>\n",
       "      <td>hate job pt think bro goofy ass audio</td>\n",
       "      <td>canada china politics government diplomatic se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7235928808166100242</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>[got, eyes, food]</td>\n",
       "      <td>[hiring, promotion, writing, writers, names, p...</td>\n",
       "      <td>got eyes food</td>\n",
       "      <td>hiring promotion writing writers names persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id  video_date  \\\n",
       "0  7273221955937914155  2023-08-30   \n",
       "1  7283080657893379334  2023-09-26   \n",
       "2  7285397643725983008  2023-10-02   \n",
       "3  7231292396573641991  2023-05-09   \n",
       "4  7235928808166100242  2023-05-22   \n",
       "\n",
       "                                      video_keywords  \\\n",
       "0  [angels, tibet, angels, tibet, dance, angels, ...   \n",
       "1  [angels, tibet, jam, republic, angels, tibet, ...   \n",
       "2  [dream, academy, angels, tibet, adela, dream, ...   \n",
       "3     [hate, job, pt, think, bro, goofy, ass, audio]   \n",
       "4                                  [got, eyes, food]   \n",
       "\n",
       "                                        nyt_keywords  \\\n",
       "0  [floyd, willie, lewis, iii, trump, donald, j, ...   \n",
       "1  [presidential, election, 2024, debates, politi...   \n",
       "2  [national, parks, monuments, seashores, bears,...   \n",
       "3  [canada, china, politics, government, diplomat...   \n",
       "4  [hiring, promotion, writing, writers, names, p...   \n",
       "\n",
       "                                     video_sentences  \\\n",
       "0  angels tibet angels tibet dance angels tibet s...   \n",
       "1  angels tibet jam republic angels tibet tutoria...   \n",
       "2  dream academy angels tibet adela dream academy...   \n",
       "3              hate job pt think bro goofy ass audio   \n",
       "4                                      got eyes food   \n",
       "\n",
       "                                       nyt_sentences  \n",
       "0  floyd willie lewis iii trump donald j willis f...  \n",
       "1  presidential election 2024 debates political r...  \n",
       "2  national parks monuments seashores bears death...  \n",
       "3  canada china politics government diplomatic se...  \n",
       "4  hiring promotion writing writers names persona...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df['video_sentences'] = comparison_df.apply(lambda row: \" \".join(row['video_keywords']), axis=1)\n",
    "comparison_df['nyt_sentences'] = comparison_df.apply(lambda row: \" \".join(row['nyt_keywords']), axis=1)\n",
    "\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cosine similarity with Semantic Analysis <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 22:46:02.604348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity function, from week 7 notebook\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosineSimilarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    V1 = np.array(vec1)\n",
    "    V2 = np.array(vec2)\n",
    "    cosine = np.dot(V1, V2)/(norm(V1)*norm(V2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       "array([[ 5.02408668e-02, -5.72159961e-02,  3.88645865e-02,\n",
       "        -6.19135611e-02, -3.03740706e-02,  5.70509210e-02,\n",
       "        -6.21422641e-02, -2.79508382e-02, -6.55337051e-02,\n",
       "        -6.32722080e-02,  2.48609297e-02,  6.93009347e-02,\n",
       "         1.28965145e-02, -3.27968933e-02,  5.60682714e-02,\n",
       "        -5.69079779e-02, -2.20257565e-02,  6.48708567e-02,\n",
       "         3.46173085e-02, -6.87998310e-02,  6.79460689e-02,\n",
       "         5.95044978e-02,  6.92275316e-02,  3.80145423e-02,\n",
       "         6.86880350e-02,  1.53036006e-02, -1.03195058e-02,\n",
       "        -4.88805249e-02, -6.08899724e-03, -2.44831592e-02,\n",
       "         5.02196886e-02,  3.00412402e-02, -7.09355762e-03,\n",
       "        -7.42765749e-03, -3.42276413e-03,  1.04430439e-02,\n",
       "         2.95333024e-02,  6.53568059e-02,  6.96141645e-02,\n",
       "         5.51910065e-02, -5.00645526e-02, -4.66123372e-02,\n",
       "        -1.05388276e-02, -3.72130200e-02, -6.04823139e-03,\n",
       "         2.21524686e-02, -3.91618907e-02,  6.89001232e-02,\n",
       "         5.43650351e-02,  6.75795898e-02,  4.84874323e-02,\n",
       "         3.55051123e-02, -6.46485984e-02, -5.81565797e-02,\n",
       "         6.35816390e-03,  5.70160747e-02,  6.67476654e-02,\n",
       "         4.44395989e-02, -5.16161732e-02,  5.44475354e-02,\n",
       "        -6.00092411e-02, -4.91336621e-02,  5.98206483e-02,\n",
       "        -5.86579517e-02, -5.17962240e-02,  4.36683334e-02,\n",
       "        -3.87205519e-02,  3.65135632e-02, -2.90763602e-02,\n",
       "         6.09740615e-02, -1.25148343e-02,  6.75166100e-02,\n",
       "         6.19534925e-02,  3.48886475e-02,  1.04415771e-02,\n",
       "        -3.80366556e-02, -6.59387978e-03,  5.23715355e-02,\n",
       "        -2.82060094e-02, -5.71699776e-02, -3.72929424e-02,\n",
       "         5.10520339e-02, -5.52312136e-02,  6.97400495e-02,\n",
       "         2.21069939e-02, -1.33042745e-02,  5.99107146e-02,\n",
       "         2.56878920e-02, -6.49066344e-02, -4.18132171e-02,\n",
       "        -3.03578023e-02,  2.57633813e-02,  1.00228703e-03,\n",
       "         1.29991528e-02,  3.24790925e-02,  6.08015992e-02,\n",
       "        -1.75333321e-02,  6.75983280e-02,  5.48102967e-02,\n",
       "        -1.89366620e-02,  6.98316395e-02,  3.22782062e-02,\n",
       "         4.37896773e-02, -5.67812519e-03,  5.05605228e-02,\n",
       "         3.84198874e-02, -3.18133831e-03, -2.82632876e-02,\n",
       "         2.69384328e-02, -4.92949737e-03, -5.89016750e-02,\n",
       "         6.43747374e-02, -2.67629120e-02,  3.09562893e-03,\n",
       "         1.96037758e-02, -2.33749039e-02,  3.03162970e-02,\n",
       "         6.84967125e-03, -6.03278764e-02, -4.47303168e-02,\n",
       "        -4.23913123e-03, -6.41225278e-02, -6.74371049e-02,\n",
       "         4.94887587e-04, -2.20669508e-02,  4.11399603e-02,\n",
       "         5.24464659e-02, -6.78619742e-02, -2.29634270e-02,\n",
       "         6.34655282e-02,  5.10818549e-02, -6.87560439e-02,\n",
       "         6.77082781e-03, -1.20679019e-02, -2.78315283e-02,\n",
       "         2.86869295e-02,  5.80811724e-02, -6.97858483e-02,\n",
       "         3.42615834e-03, -1.17583219e-02,  1.30594959e-02,\n",
       "         5.10929376e-02, -5.14350198e-02,  5.15113808e-02,\n",
       "         1.31392013e-02, -5.40171675e-02, -3.28372680e-02,\n",
       "         6.10733032e-02, -3.72735970e-02, -7.92436767e-03,\n",
       "         3.35271545e-02, -4.07538787e-02, -1.58486255e-02,\n",
       "         2.43405607e-02, -3.92285474e-02, -7.16231065e-03,\n",
       "        -6.59666508e-02, -6.35234565e-02, -2.76475213e-03,\n",
       "         6.28476292e-02,  5.20474985e-02,  5.53596094e-02,\n",
       "         4.80633676e-02, -3.74298766e-02, -6.40056208e-02,\n",
       "         3.36019993e-02,  5.48834465e-02, -5.45447506e-02,\n",
       "        -5.56624569e-02, -6.68939427e-02,  6.27251565e-02,\n",
       "         6.49505332e-02,  5.76163754e-02,  5.38077429e-02,\n",
       "        -7.33011682e-03, -3.39383483e-02,  4.88543548e-02,\n",
       "        -6.82744160e-02,  6.46246374e-02,  2.54254639e-02,\n",
       "        -9.39729158e-03,  1.13519812e-02, -5.46042696e-02,\n",
       "        -5.82016222e-02, -6.91223890e-02, -2.24408563e-02,\n",
       "         5.80717064e-02,  2.90079191e-02,  6.87747151e-02,\n",
       "         3.02877161e-03, -5.16632237e-02, -2.12284941e-02,\n",
       "        -3.32118422e-02, -6.11571819e-02,  6.23565130e-02,\n",
       "        -5.04175834e-02,  1.12599563e-02,  9.06435214e-03,\n",
       "        -1.34728309e-02,  2.92445924e-02, -6.25707731e-02,\n",
       "        -4.55853939e-02, -3.27196941e-02,  3.59091051e-02,\n",
       "         5.33345938e-02, -4.22172770e-02, -3.61737758e-02,\n",
       "        -5.36056012e-02, -2.67941952e-02, -6.67945519e-02,\n",
       "        -4.38255034e-02, -4.44811620e-02, -1.54334186e-02,\n",
       "        -7.45576061e-03,  5.74421464e-03, -6.28587753e-02,\n",
       "        -2.90759690e-02, -2.73700785e-02,  5.87780960e-02,\n",
       "         2.95521747e-02,  5.89931607e-02,  3.16903703e-02,\n",
       "         3.83243375e-02, -4.14827950e-02,  4.15398702e-02,\n",
       "        -2.87794340e-02, -3.45360078e-02,  6.56934902e-02,\n",
       "         6.64821640e-02,  5.83330020e-02, -5.33848591e-02,\n",
       "         6.09260751e-03,  5.86039275e-02, -3.51895057e-02,\n",
       "         5.63025326e-02, -4.56589833e-02,  5.53802848e-02,\n",
       "         2.60525458e-02,  4.96424399e-02,  1.13399858e-02,\n",
       "         5.43853641e-02, -5.28053083e-02,  2.00187247e-02,\n",
       "        -1.74648818e-02,  7.03181745e-03, -4.01070341e-03,\n",
       "        -5.45524396e-02, -4.53747176e-02,  1.33376438e-02,\n",
       "        -5.27109914e-02,  6.69394359e-02,  3.18441416e-05,\n",
       "        -9.44427028e-03, -4.13097814e-02, -1.31540606e-02,\n",
       "         3.37081887e-02, -6.01193272e-02,  3.87701653e-02,\n",
       "        -4.11302131e-03,  3.49623039e-02, -6.78062579e-03,\n",
       "         6.94905370e-02,  1.29505889e-02,  1.54806599e-02,\n",
       "        -6.22669943e-02,  6.83188438e-02,  1.73779158e-03,\n",
       "        -2.89776735e-02, -5.51195350e-03, -5.21162804e-03,\n",
       "        -6.52233660e-02,  6.36963695e-02,  4.91353385e-02,\n",
       "         5.59483804e-02, -6.98329136e-02, -2.60581784e-02,\n",
       "         6.77452376e-03, -6.95163235e-02,  5.81677705e-02,\n",
       "        -5.70557825e-02,  3.96027640e-02,  6.83217198e-02,\n",
       "        -2.66388934e-02,  2.79409019e-03, -1.45071130e-02,\n",
       "        -3.65699604e-02, -3.80111672e-02,  9.55964159e-03,\n",
       "        -4.37821038e-02,  6.59193322e-02,  2.09817849e-02,\n",
       "         4.19626161e-02,  6.09834418e-02,  2.96452120e-02,\n",
       "         1.02884304e-02, -2.50489358e-02,  4.95556928e-02,\n",
       "        -1.45005491e-02,  2.87584309e-02, -5.22513501e-02,\n",
       "        -1.98665634e-02,  1.27492864e-02, -4.05534506e-02,\n",
       "        -9.76651069e-03,  1.66498795e-02, -1.10090021e-02,\n",
       "        -3.56215723e-02,  5.19960299e-02, -4.75766398e-02,\n",
       "         1.75127275e-02, -4.21593105e-03, -2.29714625e-02,\n",
       "         6.32560998e-02, -3.94113511e-02, -4.29856740e-02,\n",
       "         2.37295851e-02,  6.64725155e-02, -5.45588024e-02,\n",
       "        -1.53207118e-02,  2.42130738e-02, -3.24799158e-02,\n",
       "        -6.81674927e-02, -1.32264709e-02,  4.68828669e-03,\n",
       "         3.33741792e-02, -6.77774772e-02,  1.62435044e-02,\n",
       "         6.90144673e-02,  1.33699765e-02, -1.00411028e-02,\n",
       "        -3.09257247e-02, -6.22310378e-02, -6.42691851e-02,\n",
       "         2.30344338e-03,  1.25377243e-02,  3.49910296e-02,\n",
       "        -5.93267903e-02, -3.98006029e-02, -6.40712455e-02,\n",
       "         4.70197201e-02,  4.55268137e-02, -6.22085594e-02,\n",
       "        -1.25051644e-02, -6.23980723e-02,  6.19764104e-02,\n",
       "         6.19445816e-02, -5.48228361e-02, -4.72231954e-02,\n",
       "        -1.52568547e-02,  6.27074093e-02, -5.09289233e-03,\n",
       "        -5.43994717e-02,  6.36888146e-02,  6.96477517e-02,\n",
       "         4.16509733e-02, -6.95889294e-02, -6.92817420e-02,\n",
       "        -6.90743551e-02, -5.32335825e-02,  2.01812610e-02,\n",
       "         5.97746996e-03,  6.95301294e-02,  5.95918000e-02,\n",
       "         6.32003471e-02, -2.50858767e-03,  1.07557727e-02,\n",
       "         6.63862228e-02, -5.46101481e-03, -3.52373812e-03,\n",
       "         6.41338751e-02,  3.72986645e-02, -6.47165179e-02,\n",
       "         2.94227228e-02,  6.51627034e-02, -4.13761400e-02,\n",
       "        -1.19767403e-02, -3.19983438e-02,  9.77480691e-03,\n",
       "        -6.43236861e-02, -1.12266466e-02,  3.41330729e-02,\n",
       "        -5.86582944e-02,  6.95621148e-02, -4.97219823e-02,\n",
       "         2.92471033e-02,  4.02195044e-02,  6.70655072e-02,\n",
       "         5.49670346e-02,  5.82514107e-02,  5.18304631e-02,\n",
       "        -2.73711085e-02, -1.58700962e-02, -3.25424783e-02,\n",
       "        -5.18705770e-02,  2.56725512e-02, -5.83023950e-02,\n",
       "        -1.49852363e-02, -6.19726703e-02,  2.41787881e-02,\n",
       "         2.44512036e-02, -3.93236876e-02, -2.95309965e-02,\n",
       "         4.02670279e-02, -6.92629665e-02, -1.21365357e-02,\n",
       "        -6.86684847e-02,  6.90781251e-02,  3.03094964e-02,\n",
       "         6.15894236e-02, -3.83510664e-02, -1.39221316e-02,\n",
       "        -2.36276798e-02, -3.23984362e-02, -8.94526020e-03,\n",
       "        -5.49075454e-02, -8.45296308e-03,  6.64330572e-02,\n",
       "         2.89011803e-02,  2.87485253e-02, -9.33873281e-03,\n",
       "         1.16959272e-03, -5.12110591e-02, -4.86327782e-02,\n",
       "         1.67632569e-02, -2.25988068e-02,  4.58756983e-02,\n",
       "        -6.48013949e-02, -5.24035878e-02, -2.57728901e-02,\n",
       "         4.84733582e-02, -4.39672312e-03, -6.18439950e-02,\n",
       "        -8.39546323e-03, -2.59240847e-02,  2.24805810e-02,\n",
       "         7.53671105e-04, -4.84153070e-02,  1.79791767e-02,\n",
       "        -3.09156650e-03,  3.26706395e-02, -2.07342952e-02,\n",
       "         6.64437115e-02, -4.52291928e-02,  6.75947666e-02,\n",
       "         6.22388488e-03, -5.76292910e-02, -4.37526312e-03,\n",
       "         4.04008105e-02,  4.99941856e-02, -5.90315796e-02,\n",
       "        -6.96427897e-02, -5.94395287e-02,  2.20221896e-02,\n",
       "         2.57781632e-02,  6.23228252e-02, -3.69491950e-02,\n",
       "         6.39034808e-02,  3.66566554e-02, -2.49323733e-02,\n",
       "         1.98079385e-02, -4.17069606e-02, -3.74701843e-02,\n",
       "         2.56662723e-03, -4.48187664e-02,  5.25852591e-02,\n",
       "        -3.92644107e-02,  4.30708304e-02, -5.88615844e-03,\n",
       "        -4.21856642e-02, -2.98297573e-02, -5.27147315e-02,\n",
       "        -6.08040532e-03,  5.67281106e-03, -6.22886196e-02,\n",
       "         7.00489571e-03, -2.59201974e-02,  3.14617041e-03,\n",
       "         2.20712405e-02, -6.55483920e-04,  5.81442453e-02,\n",
       "         2.27903873e-02,  5.10660708e-02, -1.62369069e-02,\n",
       "        -9.31418501e-03,  3.80897224e-02,  2.76643559e-02,\n",
       "        -6.47038966e-02,  2.96150111e-02, -5.42209968e-02,\n",
       "         5.05461097e-02,  6.70964271e-02,  6.40661865e-02,\n",
       "         6.91806376e-02, -2.71751955e-02,  6.95780367e-02,\n",
       "        -1.97564019e-03, -4.45562787e-02,  6.98161125e-02,\n",
       "         1.25132501e-02,  6.30287230e-02, -7.71803595e-03,\n",
       "         3.66969034e-03,  1.84044912e-02,  3.69395986e-02,\n",
       "        -2.25171410e-02,  3.99875976e-02,  4.94061448e-02,\n",
       "         6.62499741e-02,  3.67444791e-02,  3.54750603e-02,\n",
       "         3.31881829e-02, -6.94782808e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed([\"dream academy angels tibet adela dream academy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7273221955937914155: 0.17501032,\n",
       " 7283080657893379334: 0.23219937,\n",
       " 7285397643725983008: 0.22656588,\n",
       " 7231292396573641991: 0.01899231,\n",
       " 7235928808166100242: 0.0021175565}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cosine similarities and add them to the \n",
    "\n",
    "cosine_similarities = {}\n",
    "\n",
    "for index, row in comparison_df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    video_sentence = row['video_sentences']\n",
    "    #print(type(video_sentence))\n",
    "    nyt_sentence = row['nyt_sentences']\n",
    "    \n",
    "    # calculate embeddings for video sentence\n",
    "    video_embedding = embed([video_sentence])[0]    # not sure why??\n",
    "    nyt_embedding = embed([nyt_sentence])[0]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    cosine_sim = cosineSimilarity(video_embedding, nyt_embedding)\n",
    "\n",
    "    # add to dictionary\n",
    "    cosine_similarities[video_id] = cosine_sim\n",
    "\n",
    "cosine_similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS315 Project2",
   "language": "python",
   "name": ".project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
