{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity with Transcriptions\n",
    "\n",
    "Notebook used to find cosine similarity between video transcriptions and NYT articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_locationcreated</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_diggcount</th>\n",
       "      <th>video_sharecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>video_playcount</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_is_ad</th>\n",
       "      <th>video_stickers</th>\n",
       "      <th>author_username</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_followercount</th>\n",
       "      <th>author_followingcount</th>\n",
       "      <th>author_heartcount</th>\n",
       "      <th>author_videocount</th>\n",
       "      <th>author_diggcount</th>\n",
       "      <th>author_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jade游낼not perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jade游낼not perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26T06:32:40</td>\n",
       "      <td>15.0</td>\n",
       "      <td>PH</td>\n",
       "      <td>angels in tibet, Jam Republic, angels in tibet...</td>\n",
       "      <td>419100.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>游멇릲멇릲</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clarkie_cpm</td>\n",
       "      <td>Clarkie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jade游낼not perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02T12:23:48</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Dream Academy, angels in tibet, Adela Dream Ac...</td>\n",
       "      <td>142700.0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>s/o to dream academy for teaching me how to da...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adelajergova</td>\n",
       "      <td>AD칄LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id      video_timestamp  video_duration  \\\n",
       "0  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "1  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "2  7283080657893379334  2023-09-26T06:32:40            15.0   \n",
       "3  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "4  7285397643725983008  2023-10-02T12:23:48            37.0   \n",
       "\n",
       "  video_locationcreated                                    suggested_words  \\\n",
       "0                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "1                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "2                    PH  angels in tibet, Jam Republic, angels in tibet...   \n",
       "3                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "4                    US  Dream Academy, angels in tibet, Adela Dream Ac...   \n",
       "\n",
       "   video_diggcount  video_sharecount  video_commentcount  video_playcount  \\\n",
       "0         356300.0            5606.0               986.0        2000000.0   \n",
       "1         356300.0            5606.0               986.0        2000000.0   \n",
       "2         419100.0            3518.0               708.0        2600000.0   \n",
       "3         356300.0            5606.0               986.0        2000000.0   \n",
       "4         142700.0            1373.0               551.0        1000000.0   \n",
       "\n",
       "                                   video_description  video_is_ad  \\\n",
       "0  Replying to @jade游낼not perfect yet &  i made a ...        False   \n",
       "1  Replying to @jade游낼not perfect yet &  i made a ...        False   \n",
       "2                                                游멇릲멇릲        False   \n",
       "3  Replying to @jade游낼not perfect yet &  i made a ...        False   \n",
       "4  s/o to dream academy for teaching me how to da...        False   \n",
       "\n",
       "   video_stickers author_username author_name  author_followercount  \\\n",
       "0             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "1             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "2             NaN     clarkie_cpm     Clarkie                   NaN   \n",
       "3             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "4             NaN    adelajergova       AD칄LA                   NaN   \n",
       "\n",
       "   author_followingcount  author_heartcount  author_videocount  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4                    NaN                NaN                NaN   \n",
       "\n",
       "   author_diggcount  author_verified  \n",
       "0               NaN            False  \n",
       "1               NaN            False  \n",
       "2               NaN            False  \n",
       "3               NaN            False  \n",
       "4               NaN            False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get combined pdf to access dates\n",
    "\n",
    "cwd = os.getcwd()\n",
    "metadata_dir = f'{cwd}/../pre-processing/metadata-csv'\n",
    "metadata_files = [file for file in os.listdir(metadata_dir) if \"Sec2Gr3_\" in file]      # only get metadata files for our group\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in metadata_files:\n",
    "    file_path = os.path.join(metadata_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dir = f'{cwd}/../transcription /txt-transcripts/'\n",
    "\n",
    "transcripts = [file for file in os.listdir(transcript_dir) if file.endswith('.txt')]\n",
    "\n",
    "transcript_dict = {'video_id': [], 'transcription': []}\n",
    "\n",
    "for file in transcripts:\n",
    "    video_id = file.split('.')[0]\n",
    "    with open(os.path.join(transcript_dir, file), \"r\") as transcription_file:\n",
    "        transcription = transcription_file.read()\n",
    "\n",
    "    transcript_dict['video_id'].append(video_id)\n",
    "    transcript_dict['transcription'].append(transcription)\n",
    "\n",
    "transcript_df = pd.DataFrame(transcript_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7236076693822246170</td>\n",
       "      <td>Outro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7295142634719415595</td>\n",
       "      <td>Yeah, yeah, uh, hang up. Huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7305273374962371882</td>\n",
       "      <td>Here's Curry. Curry looking to take Wembley. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7299203592739704106</td>\n",
       "      <td>We have an awesome bathtub. It's a jacuzzi tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7295523111103991083</td>\n",
       "      <td>Lalalilililililililililililililililililililil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id                                      transcription\n",
       "0  7236076693822246170                                              Outro\n",
       "1  7295142634719415595                      Yeah, yeah, uh, hang up. Huh?\n",
       "2  7305273374962371882   Here's Curry. Curry looking to take Wembley. ...\n",
       "3  7299203592739704106   We have an awesome bathtub. It's a jacuzzi tu...\n",
       "4  7295523111103991083   Lalalilililililililililililililililililililil..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = combined_df[['video_id', 'video_timestamp']]\n",
    "date_df['video_date'] = date_df['video_timestamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity function, from week 7 notebook\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosineSimilarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    V1 = np.array(vec1)\n",
    "    V2 = np.array(vec2)\n",
    "    cosine = np.dot(V1, V2)/(norm(V1)*norm(V2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_nyt_articles_revised import filter_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract(headline, date):\n",
    "    \"\"\"Given a NYT headline and date, returns the abstract for comparison\"\"\"\n",
    "    nyt_df = filter_by_date(date)\n",
    "\n",
    "    for index, nyt_row in nyt_df.iterrows():\n",
    "        if nyt_row['headline'] == headline:\n",
    "            abstract = nyt_row['abstract']\n",
    "\n",
    "    return abstract\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with video_id, date, transcription, and abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarities and add them to the dictionary\n",
    "\n",
    "cosine_similarities = {}\n",
    "\n",
    "for index, row in comparison_df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    video_sentence = row['video_sentences']\n",
    "    #print(type(video_sentence))\n",
    "    nyt_sentence = row['nyt_sentences']\n",
    "    \n",
    "    # using universal sentence encoder\n",
    "    #video_embedding = embed([video_sentence])[0]    # not sure why??\n",
    "    #nyt_embedding = embed([nyt_sentence])[0]\n",
    "\n",
    "    #using sbert model \n",
    "    video_embedding = sbert_model.encode([video_sentence])[0]\n",
    "    nyt_embedding = sbert_model.encode([nyt_sentence])[0]\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    cosine_sim = cosineSimilarity(video_embedding, nyt_embedding)\n",
    "\n",
    "    # add to dictionary\n",
    "    cosine_similarities[video_id] = cosine_sim\n",
    "\n",
    "cosine_similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS315 Project2",
   "language": "python",
   "name": ".project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
