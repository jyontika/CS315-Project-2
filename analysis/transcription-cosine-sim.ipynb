{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity with Transcriptions\n",
    "\n",
    "Notebook used to find cosine similarity between video transcriptions and NYT articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_locationcreated</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_diggcount</th>\n",
       "      <th>video_sharecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>video_playcount</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_is_ad</th>\n",
       "      <th>video_stickers</th>\n",
       "      <th>author_username</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_followercount</th>\n",
       "      <th>author_followingcount</th>\n",
       "      <th>author_heartcount</th>\n",
       "      <th>author_videocount</th>\n",
       "      <th>author_diggcount</th>\n",
       "      <th>author_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jade游낼not perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jade游낼not perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7283080657893379334</td>\n",
       "      <td>2023-09-26T06:32:40</td>\n",
       "      <td>15.0</td>\n",
       "      <td>PH</td>\n",
       "      <td>angels in tibet, Jam Republic, angels in tibet...</td>\n",
       "      <td>419100.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>游멇릲멇릲</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clarkie_cpm</td>\n",
       "      <td>Clarkie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7273221955937914155</td>\n",
       "      <td>2023-08-30T16:56:01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>angels in tibet, angels in tibet dance, angels...</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Replying to @jade游낼not perfect yet &amp;  i made a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebeaulexx</td>\n",
       "      <td>beaulexx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7285397643725983008</td>\n",
       "      <td>2023-10-02T12:23:48</td>\n",
       "      <td>37.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Dream Academy, angels in tibet, Adela Dream Ac...</td>\n",
       "      <td>142700.0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>s/o to dream academy for teaching me how to da...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adelajergova</td>\n",
       "      <td>AD칄LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id      video_timestamp  video_duration  \\\n",
       "0  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "1  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "2  7283080657893379334  2023-09-26T06:32:40            15.0   \n",
       "3  7273221955937914155  2023-08-30T16:56:01            37.0   \n",
       "4  7285397643725983008  2023-10-02T12:23:48            37.0   \n",
       "\n",
       "  video_locationcreated                                    suggested_words  \\\n",
       "0                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "1                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "2                    PH  angels in tibet, Jam Republic, angels in tibet...   \n",
       "3                    US  angels in tibet, angels in tibet dance, angels...   \n",
       "4                    US  Dream Academy, angels in tibet, Adela Dream Ac...   \n",
       "\n",
       "   video_diggcount  video_sharecount  video_commentcount  video_playcount  \\\n",
       "0         356300.0            5606.0               986.0        2000000.0   \n",
       "1         356300.0            5606.0               986.0        2000000.0   \n",
       "2         419100.0            3518.0               708.0        2600000.0   \n",
       "3         356300.0            5606.0               986.0        2000000.0   \n",
       "4         142700.0            1373.0               551.0        1000000.0   \n",
       "\n",
       "                                   video_description  video_is_ad  \\\n",
       "0  Replying to @jade游낼not perfect yet &  i made a ...        False   \n",
       "1  Replying to @jade游낼not perfect yet &  i made a ...        False   \n",
       "2                                                游멇릲멇릲        False   \n",
       "3  Replying to @jade游낼not perfect yet &  i made a ...        False   \n",
       "4  s/o to dream academy for teaching me how to da...        False   \n",
       "\n",
       "   video_stickers author_username author_name  author_followercount  \\\n",
       "0             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "1             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "2             NaN     clarkie_cpm     Clarkie                   NaN   \n",
       "3             NaN     thebeaulexx    beaulexx                   NaN   \n",
       "4             NaN    adelajergova       AD칄LA                   NaN   \n",
       "\n",
       "   author_followingcount  author_heartcount  author_videocount  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4                    NaN                NaN                NaN   \n",
       "\n",
       "   author_diggcount  author_verified  \n",
       "0               NaN            False  \n",
       "1               NaN            False  \n",
       "2               NaN            False  \n",
       "3               NaN            False  \n",
       "4               NaN            False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get combined pdf to access dates\n",
    "\n",
    "cwd = os.getcwd()\n",
    "metadata_dir = f'{cwd}/../pre-processing/metadata-csv'\n",
    "metadata_files = [file for file in os.listdir(metadata_dir) if \"Sec2Gr3_\" in file]      # only get metadata files for our group\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in metadata_files:\n",
    "    file_path = os.path.join(metadata_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dir = f'{cwd}/../transcription/txt-transcripts/'\n",
    "\n",
    "transcripts = [file for file in os.listdir(transcript_dir) if file.endswith('.txt')]\n",
    "\n",
    "transcript_dict = {'video_id': [], 'transcription': []}\n",
    "\n",
    "for file in transcripts:\n",
    "    video_id = file.split('.')[0]\n",
    "    with open(os.path.join(transcript_dir, file), \"r\") as transcription_file:\n",
    "        transcription = transcription_file.read()\n",
    "\n",
    "    transcript_dict['video_id'].append(video_id)\n",
    "    transcript_dict['transcription'].append(transcription)\n",
    "\n",
    "transcript_df = pd.DataFrame(transcript_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7300021255258901806</td>\n",
       "      <td>I'm sorry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7236076693822246170</td>\n",
       "      <td>Outro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7301769517041126702</td>\n",
       "      <td>Okay, right. No, I'm getting with this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7289191984529575214</td>\n",
       "      <td>People, open your eyes. We are supporting gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7297432141485444394</td>\n",
       "      <td>The Zionist argument we will address today is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id                                      transcription\n",
       "0  7300021255258901806                                         I'm sorry.\n",
       "1  7236076693822246170                                              Outro\n",
       "2  7301769517041126702            Okay, right. No, I'm getting with this.\n",
       "3  7289191984529575214   People, open your eyes. We are supporting gen...\n",
       "4  7297432141485444394   The Zionist argument we will address today is..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/rqxxrf3n6zq58_z0ng_2hbhm0000gn/T/ipykernel_59398/3389850981.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  date_df['video_date'] = date_df['video_timestamp'].str[:10]\n"
     ]
    }
   ],
   "source": [
    "date_df = combined_df[['video_id', 'video_timestamp']]\n",
    "date_df['video_date'] = date_df['video_timestamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_df = date_df.set_index('video_id')\n",
    "# transcript_df = transcript_df.set_index('video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7273221955937914155\n",
       "1        7273221955937914155\n",
       "2        7283080657893379334\n",
       "3        7273221955937914155\n",
       "4        7285397643725983008\n",
       "                ...         \n",
       "24910    7283846172425407750\n",
       "24911    7285527057394584863\n",
       "24912    7284024264334806315\n",
       "24913    7284462467290303787\n",
       "24914    7286843613030518059\n",
       "Name: video_id, Length: 24915, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.loc[:, 'video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/rqxxrf3n6zq58_z0ng_2hbhm0000gn/T/ipykernel_59398/1140099450.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  date_df['video_id'] = date_df.loc[:, 'video_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "date_df['video_id'] = date_df.loc[:, 'video_id'].astype(str)\n",
    "transcript_df['video_id'] = transcript_df['video_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcription</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7300021255258901806</td>\n",
       "      <td>I'm sorry.</td>\n",
       "      <td>2023-11-10T21:11:00</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7236076693822246170</td>\n",
       "      <td>Outro</td>\n",
       "      <td>2023-05-22T14:33:29</td>\n",
       "      <td>2023-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7301769517041126702</td>\n",
       "      <td>Okay, right. No, I'm getting with this.</td>\n",
       "      <td>2023-11-15T14:15:04</td>\n",
       "      <td>2023-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7289191984529575214</td>\n",
       "      <td>People, open your eyes. We are supporting gen...</td>\n",
       "      <td>2023-10-12T17:47:59</td>\n",
       "      <td>2023-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7297432141485444394</td>\n",
       "      <td>The Zionist argument we will address today is...</td>\n",
       "      <td>2023-11-03T22:43:55</td>\n",
       "      <td>2023-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_id                                      transcription  \\\n",
       "0  7300021255258901806                                         I'm sorry.   \n",
       "1  7236076693822246170                                              Outro   \n",
       "2  7301769517041126702            Okay, right. No, I'm getting with this.   \n",
       "3  7289191984529575214   People, open your eyes. We are supporting gen...   \n",
       "4  7297432141485444394   The Zionist argument we will address today is...   \n",
       "\n",
       "       video_timestamp  video_date  \n",
       "0  2023-11-10T21:11:00  2023-11-10  \n",
       "1  2023-05-22T14:33:29  2023-05-22  \n",
       "2  2023-11-15T14:15:04  2023-11-15  \n",
       "3  2023-10-12T17:47:59  2023-10-12  \n",
       "4  2023-11-03T22:43:55  2023-11-03  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_date_df = pd.merge(transcript_df, date_df, on='video_id')\n",
    "transcript_date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 2)\n",
      "(432, 4)\n"
     ]
    }
   ],
   "source": [
    "print(transcript_df.shape)\n",
    "print(transcript_date_df.shape) ### PROBLEM!! SOLVE THIS: why are there more rows now??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity function, from week 7 notebook\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosineSimilarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    V1 = np.array(vec1)\n",
    "    V2 = np.array(vec2)\n",
    "    cosine = np.dot(V1, V2)/(norm(V1)*norm(V2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_nyt_articles_revised import filter_by_date, filter_by_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_nyt(nyt_df, col_name, trans_embedding):\n",
    "    max_similarity = -1  # initialize maximums\n",
    "    max_index = -1\n",
    "    for index, nyt_row in nyt_df.iterrows():\n",
    "        cosine_similarities = {}\n",
    "        nyt_embedding = embed([nyt_row[col_name]])[0]               # universal sentence encoder\n",
    "    \n",
    "         # calculate cosine similarity\n",
    "        cosine_sim = cosineSimilarity(trans_embedding, nyt_embedding)\n",
    "\n",
    "        if cosine_sim > max_similarity:\n",
    "            max_similarity = cosine_sim\n",
    "            max_index = index\n",
    "            top_row = nyt_df.loc[max_index]\n",
    "    headline = top_row['headline']\n",
    "    \n",
    "    print(f\"Index of Maximum Cosine Similarity for {col_name}:\", max_index)\n",
    "    print(f\"Maximum Cosine Similarity for {col_name}:\", max_similarity)\n",
    "\n",
    "    return (max_similarity, headline, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    \"\"\"\n",
    "    Helper function, takes video transcript and splits into words, removes punctuation, and stop words\n",
    "    \"\"\"\n",
    "    if pd.isna(description):  \n",
    "        return [] \n",
    "    \n",
    "    # remove numbers from the text\n",
    "    description = re.sub(r'\\d+', '', description)\n",
    "\n",
    "    # split the description into words\n",
    "    words = description.split()\n",
    "    \n",
    "    # make everything lowercase\n",
    "    cleaned_words = [word.lower() for word in words]\n",
    "    \n",
    "    # remove stop words\n",
    "    cleaned_words = [word for word in cleaned_words if word not in stop_words]\n",
    "\n",
    "    # remove empty strings\n",
    "    cleaned_words = [word for word in cleaned_words if word]\n",
    "\n",
    "    sentence = \" \".join(cleaned_words)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_keywords(text):\n",
    "    \"\"\"Split text into individual keywords based on whitespace and punctuation, remove stop words\"\"\"\n",
    "    if pd.isna(text):  # check if text is NaN\n",
    "        return []  \n",
    "    \n",
    "    # split text into individual keywords based on whitespace and punctuation\n",
    "    keywords = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    # remove stop words\n",
    "    cleaned_words = [word.lower() for word in keywords if word not in stop_words]\n",
    "    \n",
    "    return cleaned_words\n",
    "\n",
    "def clean_headline(text):\n",
    "    \"\"\"Split headline into individual words based on whitespace and punctuation, remove stop words\"\"\"\n",
    "    if pd.isna(text):  # check if text is NaN\n",
    "        return []  \n",
    "    \n",
    "    # remove numbers from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # split text into individual keywords based on whitespace\n",
    "    keywords = text.split()\n",
    "\n",
    "    # remove stop words\n",
    "    cleaned_words = [word.lower() for word in keywords if word not in stop_words]\n",
    "    \n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_videos = len(transcript_date_df)\n",
    "for index, row in transcript_date_df.iterrows():\n",
    "    print(f\"Processing video {index+1}/{total_num_videos}, video id: {row['video_id']}\")\n",
    "\n",
    "    transcript_embedding = embed([row['transcription']])[0]              # universal sentence encoder\n",
    "    nyt_df = filter_by_week(row['video_date'])\n",
    "\n",
    "    ## Part 1: transcription comparison to headline, abstract, lead_paragraph\n",
    "    headline_comp = cosine_sim_nyt(nyt_df, 'headline', transcript_embedding)\n",
    "    abstract_comp = cosine_sim_nyt(nyt_df, 'abstract', transcript_embedding)\n",
    "    leadpara_comp = cosine_sim_nyt(nyt_df, 'lead_paragraph', transcript_embedding)\n",
    "\n",
    "    transcript_date_df['headline_sim'] = headline_comp[0]\n",
    "    transcript_date_df['abstract_sim'] = abstract_comp[0]\n",
    "    transcript_date_df['leadpara_sim'] = leadpara_comp[0]\n",
    "\n",
    "    max = -1\n",
    "    top_headline = 'xxx'\n",
    "    type_comp = 'yyy'\n",
    "    for headline, cosine_sim, col in [headline_comp, abstract_comp, leadpara_comp]:\n",
    "        if cosine_sim > max:\n",
    "            max = cosine_sim\n",
    "            top_headline = headline\n",
    "            type_comp = col\n",
    "    \n",
    "    transcript_date_df['top_cosine_sim'] = max\n",
    "    transcript_date_df['top_headline'] = top_headline\n",
    "    transcript_date_df['top_headline_fromtype'] = type_comp\n",
    "\n",
    "    ## Part 2: transcription keyword comparison to NYT keywords (revised by us)\n",
    "    nyt_df['keywords_cleaned'] = nyt_df['keywords'].apply(split_keywords)\n",
    "    nyt_df['headline_cleaned'] = nyt_df['headline'].apply(clean_headline)\n",
    "    nyt_df['nyt_keywords'] = nyt_df['keywords_cleaned'] + nyt_df['headline_cleaned']\n",
    "    nyt_df['article_sentence'] = nyt_df.apply(lambda row: ' '.join(row['keywords_cleaned'] + row['headline_cleaned']), axis=1)\n",
    "    \n",
    "    transcription_key_sen = clean_transcription(row['trancription'])\n",
    "    trans_key_embedding = embed([transcription_key_sen])[0]\n",
    "\n",
    "    # find cosine similarity for each article \n",
    "    max_sim_keywords = -1  # initialize maximums\n",
    "    max_index_keywords = -1\n",
    "    for index2, nyt_row in nyt_df.iterrows():\n",
    "        cosine_similarities_kyewords = {}\n",
    "        nyt_embedding = embed([nyt_row['article_sentence']])[0]               # universal sentence encoder\n",
    "    \n",
    "         # calculate cosine similarity\n",
    "        cosine_sim_key = cosineSimilarity(trans_key_embedding, nyt_embedding)\n",
    "\n",
    "        if cosine_sim_key > max_sim_keywords:\n",
    "            max_sim_keywords = cosine_sim_key\n",
    "            max_index_keywords = index2\n",
    "            top_row_key = nyt_df.loc[max_index_keywords]\n",
    "    headline_key = top_row_key['headline']\n",
    "    \n",
    "    print(\"Index of Maximum Cosine Similarity for Keywords:\", max_index_keywords)\n",
    "    print(\"Maximum Cosine Similarity for Keywords:\", max_sim_keywords)\n",
    "\n",
    "    transcript_date_df['top_cosine_sim_keywords'] = max_sim_keywords\n",
    "    transcript_date_df['top_headline_keywords'] = headline_key\n",
    "    transcript_date_df['transcript_keywords'] = transcription_key_sen\n",
    "    transcript_date_df['top_nyt_article_keywords'] = top_row_key['article_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_date_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
